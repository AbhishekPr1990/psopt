#include "psopt.h"




int NLP_interface(
         Alg& algorithm,
         DMatrix* x0,
         double (*f)(DMatrix&, Workspace*),
	 void (*g)(DMatrix&,DMatrix*, Workspace*),
	 int nlp_ncons,
	 int nlp_neq  ,
	 DMatrix* xlb,
	 DMatrix* xub,
         DMatrix* lambda,
         int hotflag,
         int iprint,
         Workspace* workspace,
         void* user_data
         )
{
    Prob *problem = workspace->problem;
    Sol*  solution= workspace->solution;

    int  i;

    if ( algorithm.nlp_method=="SNOPT" )
    {

#ifdef USE_SNOPT
//  snoptProblem psocProb;
  // Allocate and initialize;
  int ii, k;

  integer n     =  length(*x0);
  integer neF   =  nlp_ncons+1;
  integer lenA  =  (nlp_ncons+1)*n;

  integer *iAfun = (integer*) my_calloc(lenA,sizeof(integer));
  integer *jAvar = (integer*) my_calloc(lenA,sizeof(integer));
  doublereal *A  = (doublereal*) my_calloc(lenA,sizeof(doublereal));


  integer lenG   = lenA;
  integer *iGfun = (integer*) my_calloc(lenG,sizeof(integer));
  integer *jGvar = (integer*) my_calloc(lenG,sizeof(integer));


  doublereal *x     = (doublereal*) my_calloc(n,sizeof(doublereal));
  doublereal *xlow  = (doublereal*) my_calloc(n,sizeof(doublereal));
  doublereal *xupp  = (doublereal*) my_calloc(n,sizeof(doublereal));
  doublereal *xmul  = (doublereal*) my_calloc(n,sizeof(doublereal));
  integer   *xstate = (integer*)    my_calloc(n,sizeof(integer));

  doublereal *F     = (doublereal*) my_calloc(neF,sizeof(doublereal));
  doublereal *Flow  = (doublereal*) my_calloc(neF,sizeof(doublereal));
  doublereal *Fupp  = (doublereal*) my_calloc(neF,sizeof(doublereal));
  doublereal *Fmul  = (doublereal*) my_calloc(neF,sizeof(doublereal));
  integer   *Fstate = (integer*)    my_calloc(neF,sizeof(integer));


  integer nxnames = 1;
  integer nFnames = 1;
  char *xnames = (char*) my_calloc(nxnames*8, sizeof(char));
  char *Fnames = (char*) my_calloc(nFnames*8, sizeof(char));


  integer    ObjRow = 1;
  doublereal ObjAdd = 0;

  doublereal InfValue = 1.0e20;

  memcpy(xlow, xlb->GetPr(), n*sizeof(double) );
  memcpy(xupp, xub->GetPr(), n*sizeof(double) );

  for (ii=0;ii<n;ii++) {
      x[ii]=0.0;
      xstate[ii]=3;
  }

  Flow[0] = -InfValue;
  Fupp[0] =  InfValue;
  Fmul[0] =  0.0;

  get_constraint_bounds( &Flow[1], &Fupp[1], workspace );


  for (ii=1; ii<neF ; ii++) {
     Fmul[ii] = (*lambda)(ii);
  }

  for (ii=0; ii<neF ; ii++) {
     Fstate[ii] = 0;
  }

  memcpy( x, x0->GetPr(), n*sizeof(double) );

// ************* C INTERFACE ************************
  integer Cold = 0, Basis = 1, Warm = 2;
  integer StartOption;
  integer    iSpecs = 4,  spec_len;
  integer    iSumm  = 6;
  integer    iPrint = 1,  prnt_len;

  integer    INFO;
  integer    neA, neG;

  integer    nxname = 1, nFname = 1, npname;
  char       Prob[200];

  integer    minrw, miniw, mincw;
  integer    lenrw = 4000*(neF+n), leniw = 2000*(neF+n), lencw = 1000;
  doublereal *rw  = (doublereal*) my_calloc(lenrw, sizeof(doublereal));
  integer    *iw  = (integer*)    my_calloc(leniw, sizeof(integer));

  char       cw[8*500];

  char       printname[200];
  char       specname[200];

  integer    nS, nInf;
  doublereal sInf;
  integer    DerOpt, Major, iSum, iPrt, strOpt_len;
  char       strOpt[200];
  integer    IterOpt;

  if ( !algorithm.print_level )
  {
  	iSumm  = 0;
	iPrint = 0;
  }

  /* open output files using snfilewrappers.[ch] */
  sprintf(specname ,   "%s", "psopt.spc");   spec_len = strlen(specname);
  sprintf(printname,   "%s", "psopt.out");   prnt_len = strlen(printname);

  /* Open the print file, fortran style */
  snopenappend_
    ( &iPrint, printname,   &INFO, prnt_len );

  sninit_
    ( &iPrint, &iSumm, cw, &lencw, iw, &leniw, rw, &lenrw, 8*500 );

  sprintf(Prob,"%s",problem->name.c_str());

  workspace->jac_done = 0;

  snjac_
    ( &INFO, &neF, &n,  snPSOPTusrf_,
      iAfun, jAvar, &lenA, &neA, A,
      iGfun, jGvar, &lenG, &neG,
      x, xlow, xupp, &mincw, &miniw, &minrw,
      cw, &lencw, iw, &leniw, rw, &lenrw,
      cw, &lencw, iw, &leniw, rw, &lenrw,
      8*500, 8*500 );

  // Store co-ordinates of nonlinear Jacobian

  for(k=0; k<neG; k++) {
        workspace->iGfun[k] = (unsigned int) iGfun[k];
        workspace->jGvar[k] = (unsigned int) jGvar[k];
  }

  (*workspace->Gsp).Resize(neF,n,neG);

  if ( useAutomaticDifferentiation(algorithm) )
  {
     adouble* xad  = workspace->xad;
     adouble* fgad = workspace->fgad;
     double*    fg = workspace->fg;

     /* Tracing of function fg() */
     trace_on(workspace->tag_fg);
     for(i=0;i<n;i++)
		xad[i] <<= x[i];

     fg_ad(xad, fgad, workspace);

     for(i=0;i<neF;i++)
	fgad[i] >>= fg[i];
     trace_off();

#ifdef ADOLC_VERSION_1
     sparse_jac(workspace->tag_fg, neF, n, 0, x, &workspace->F_nnz, &workspace->iGfun2, &workspace->jGvar2, &workspace->G2);
#endif


#ifdef ADOLC_VERSION_2
    int options[4];
    options[0]=0; options[1]=0; options[2]=0;options[3]=0;
    sparse_jac(workspace->tag_fg, neF, n, 0, x, &workspace->F_nnz, &workspace->iGfun2, &workspace->jGvar2, &workspace->G2, options);
#endif

     sprintf(workspace->text,"\nJacobian sparsity detected using ADOLC:");
     psopt_print(workspace,workspace->text);

     double jsratio = (double) ((double)  workspace->F_nnz/((double) (n*neF)));

     if (jsratio > workspace->algorithm->jac_sparsity_ratio) {
           sprintf(workspace->text, "increase algorithm.jac_sparsity_ratio to just above %f", jsratio);
           error_message(workspace->text);
     }

     sprintf(workspace->text,"\n%i nonzero elements out of %li [ratio=%f]\n", workspace->F_nnz, n*neF, jsratio);
     psopt_print(workspace,workspace->text);


      for (i=0;i<workspace->F_nnz;i++) {
          	  workspace->iGfun1[i] = workspace->iGfun2[i]+1;
        	  workspace->jGvar1[i] = workspace->jGvar2[i]+1;
      }

  }


  workspace->jac_done=1;

  int * iAfuni = (int*) my_calloc(neA, sizeof(int) );
  int * jAvari = (int*) my_calloc(neA, sizeof(int) );

  for (i=0; i< neA; i++) {
       iAfuni[i] = iAfun[i];
       jAvari[i] = jAvar[i];
  }

  SparseMatrix As(A, neF, n, neA, iAfuni, jAvari);

//  As.SaveSparsityPattern("SNOPT_Linear_pattern.txt");

  workspace->As = &As;


  DerOpt = 0;
  iPrt   = 0;
  iSum   = 0;
  sprintf(strOpt,"%s","Derivative option");
  strOpt_len = strlen(strOpt);
  snseti_
    ( strOpt, &DerOpt, &iPrt, &iSum, &INFO,
      cw, &lencw, iw, &leniw, rw, &lenrw, strOpt_len, 8*500 );



  IterOpt = workspace->algorithm->nlp_iter_max;
  iPrt   = 0;
  iSum   = 0;
  sprintf(strOpt,"%s","Major iterations limit");
  strOpt_len = strlen(strOpt);
  snseti_
    ( strOpt, &IterOpt, &iPrt, &iSum, &INFO,
      cw, &lencw, iw, &leniw, rw, &lenrw, strOpt_len, 8*500 );
  sprintf(strOpt,"%s","Minor iterations limit");
  strOpt_len = strlen(strOpt);
  snseti_
    ( strOpt, &IterOpt, &iPrt, &iSum, &INFO,
      cw, &lencw, iw, &leniw, rw, &lenrw, strOpt_len, 8*500 );
  sprintf(strOpt,"%s","Iterations limit");
  IterOpt = 50*IterOpt;
  strOpt_len = strlen(strOpt);
  snseti_
    ( strOpt, &IterOpt, &iPrt, &iSum, &INFO,
      cw, &lencw, iw, &leniw, rw, &lenrw, strOpt_len, 8*500 );
  if (!algorithm.print_level) {
  	sprintf(strOpt,"%s","Major print level 0");
  	IterOpt = 0;
  	strOpt_len = strlen(strOpt);
        snset_
        ( strOpt, &iPrt, &iSum, &INFO,
            cw, &lencw, iw, &leniw, rw, &lenrw, strOpt_len, 8*500 );
  	sprintf(strOpt,"%s","Minor print level 0");
  	IterOpt = 0;
  	strOpt_len = strlen(strOpt);
        snset_
        ( strOpt, &iPrt, &iSum, &INFO,
            cw, &lencw, iw, &leniw, rw, &lenrw, strOpt_len, 8*500 );
  }

  // Set some extra options

  sprintf(strOpt,"%s","LU complete pivoting");
  strOpt_len = strlen(strOpt);
  snset_
    ( strOpt, &iPrt, &iSum, &INFO,
      cw, &lencw, iw, &leniw, rw, &lenrw, strOpt_len, 8*500 );



  /*     ------------------------------------------------------------------ */
  /*     Go for it                                                          */
  /*     ------------------------------------------------------------------ */

  if (hotflag) StartOption=Warm;
  else StartOption=Cold;

  snopta_
    ( &StartOption, &neF, &n, &nxname, &nFname,
      &ObjAdd, &ObjRow, Prob,  snPSOPTusrf_,
      iAfun, jAvar, &lenA, &neA, A,
      iGfun, jGvar, &lenG, &neG,
      xlow, xupp, xnames, Flow, Fupp, Fnames,
      x, xstate, xmul, F, Fstate, Fmul,
      &INFO, &mincw, &miniw, &minrw,
      &nS, &nInf, &sInf,
      cw, &lencw, iw, &leniw, rw, &lenrw,

      cw, &lencw, iw, &leniw, rw, &lenrw,
      npname, 8*nxname, 8*nFname,
      8*500, 8*500);

   solution->nlp_return_code = int (INFO/10);

// *************************************************


// Copy results...

  memcpy( x0->GetPr(), x, n*sizeof(double) );

  for(ii=0;ii<n;ii++) solution->xad[ii] = x[ii];


  for (ii=1;ii<neF;ii++) {
       (*lambda)(ii) = Fmul[ii];
  }



  return 0;

#else
        sprintf(workspace->text,"\nSNOPT method has been specified but not linked");
        error_message(workspace->text);
#endif

    }

    else if ( algorithm.nlp_method=="IPOPT" )
    {

#ifdef USE_IPOPT


  // Create a new instance of nlp
  SmartPtr<TNLP> mynlp = new IPOPT_PSOPT(workspace, user_data);

  // Create a new instance of IpoptApplication
  SmartPtr<IpoptApplication> app = new IpoptApplication();

  // Change some options
  app->Options()->SetNumericValue("tol", workspace->algorithm->nlp_tolerance );
  app->Options()->SetStringValue("mu_strategy", "adaptive");
  app->Options()->SetStringValue("output_file", "ipopt.out");
  app->Options()->SetStringValue("nlp_scaling_method","gradient-based");
  app->Options()->SetNumericValue("max_cpu_time", workspace->algorithm->ipopt_max_cpu_time );


  if ( useAutomaticDifferentiation(algorithm) && algorithm.hessian=="exact" ) {
     app->Options()->SetStringValue("hessian_approximation", "exact");
  }
  else {
     app->Options()->SetStringValue("hessian_approximation", "limited-memory");
  }

  if (algorithm.print_level==0) {
      app->Options()->SetIntegerValue("print_level", 0);
  }
  else if (algorithm.print_level>0) {
      app->Options()->SetIntegerValue("print_level", 5);
  }

  app->Options()->SetIntegerValue("max_iter", workspace->algorithm->nlp_iter_max);
  if (hotflag) {
     app->Options()->SetStringValue("warm_start_init_point", "yes");
  }
  else {
	app->Options()->SetStringValue("warm_start_init_point", "no");
  }

  // Intialize the IpoptApplication and process the options
  ApplicationReturnStatus status;
  status = app->Initialize();
  if (status != Solve_Succeeded) {
    printf("\n\n*** Error during initialization!\n");
    return (int) status;
  }

  // Ask Ipopt to solve the problem
  status = app->OptimizeTNLP(mynlp);

  if (status == Solve_Succeeded) {
    psopt_print(workspace,"\n\n*** The problem solved!\n");
  }
  else {
    psopt_print(workspace,"\n\n*** The problem FAILED!\n");
  }

  // As the SmartPtrs go out of scope, the reference count
  // will be decremented and the objects will automatically
  // be deleted.

  solution->nlp_return_code = (int) status;

  return (int) status;


#else
        sprintf(workspace->text,"\nIPOPT method has been specified but not linked");
        error_message(workspace->text);
#endif


    }

    else {
        sprintf(workspace->text,"\n Incorrect NLP method has been specified");
        error_message(workspace->text);
    }

    return 0;

}


